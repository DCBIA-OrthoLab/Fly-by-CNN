{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "413b1545-57a8-4987-bfbc-4eb671f98a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import monai\n",
    "from monai.data import ArrayDataset, create_test_image_2d, decollate_batch\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AddChannel,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    RandRotate90,\n",
    "    RandSpatialCrop,\n",
    "    ScaleIntensity,\n",
    "    EnsureType,\n",
    ")\n",
    "from monai.visualize import plot_2d_or_3d_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d17ddf4-0d9f-4478-901c-7615ca59ffdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "monai.config.print_config()\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "\n",
    "# create a temporary directory and 40 random image, mask pairs\n",
    "print(f\"generating synthetic data to {tempdir} (this may take a while)\")\n",
    "for i in range(40):\n",
    "    im, seg = create_test_image_2d(128, 128, num_seg_classes=1)\n",
    "    Image.fromarray((im * 255).astype(\"uint8\")).save(os.path.join(tempdir, f\"img{i:d}.png\"))\n",
    "    Image.fromarray((seg * 255).astype(\"uint8\")).save(os.path.join(tempdir, f\"seg{i:d}.png\"))\n",
    "\n",
    "images = sorted(glob(os.path.join(tempdir, \"img*.png\")))\n",
    "segs = sorted(glob(os.path.join(tempdir, \"seg*.png\")))\n",
    "#os.system('nautilus /tmp/')\n",
    "\n",
    "# define transforms for image and segmentation\n",
    "train_imtrans = Compose(  # Training\n",
    "    [\n",
    "        LoadImage(image_only=True), # only image data, no header dict\n",
    "        AddChannel(), # transforms shape (h,w) into (1,h,w)\n",
    "        ScaleIntensity(),\n",
    "        RandSpatialCrop((96, 96), random_size=False),\n",
    "        #RandRotate90(prob=0.5, spatial_axes=(0, 1)),\n",
    "        EnsureType(),  #Ensure input data to be pytorch tensor\n",
    "    ]\n",
    ")\n",
    "train_segtrans = Compose(\n",
    "    [\n",
    "        LoadImage(image_only=True),\n",
    "        AddChannel(),\n",
    "        ScaleIntensity(),\n",
    "        RandSpatialCrop((96, 96), random_size=False),\n",
    "        #RandRotate90(prob=0.5, spatial_axes=(0, 1)),\n",
    "        EnsureType(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_imtrans = Compose(  # Validation\n",
    "    [\n",
    "        LoadImage(image_only=True), \n",
    "        AddChannel(), \n",
    "        ScaleIntensity(), \n",
    "        EnsureType()\n",
    "    ]\n",
    ")\n",
    "val_segtrans = Compose(\n",
    "    [\n",
    "        LoadImage(image_only=True), \n",
    "        AddChannel(), \n",
    "        ScaleIntensity(), \n",
    "        EnsureType()\n",
    "    ]\n",
    ")\n",
    "\n",
    "# define array dataset, data loader\n",
    "\n",
    "\n",
    "check_ds = ArrayDataset(images, train_imtrans, segs, train_segtrans)\n",
    "check_loader = DataLoader(check_ds, batch_size=10, num_workers=2, pin_memory=torch.cuda.is_available())\n",
    "im, seg = monai.utils.misc.first(check_loader)\n",
    "print (\"type check ds : \", type(check_ds))\n",
    "print (\"type im : \",type(im))\n",
    "print(im.shape, seg.shape)\n",
    "\n",
    "# create a training data loader\n",
    "train_ds = ArrayDataset(images[:20], train_imtrans, segs[:20], train_segtrans)  # ensures same seeds in the randomized transforms\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=8, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "\n",
    "# create a validation data loader\n",
    "val_ds = ArrayDataset(images[-20:], val_imtrans, segs[-20:], val_segtrans)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, num_workers=4, pin_memory=torch.cuda.is_available())\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
    "post_trans = Compose([EnsureType(), Activations(sigmoid=True), AsDiscrete(threshold_values=True)])\n",
    "\n",
    "# create UNet, DiceLoss and Adam optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = monai.networks.nets.UNet(\n",
    "    spatial_dims=2,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    ").to(device)\n",
    "loss_function = monai.losses.DiceLoss(sigmoid=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-3)\n",
    "\n",
    "# start a typical PyTorch training\n",
    "val_interval = 2\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = list()\n",
    "metric_values = list()\n",
    "writer = SummaryWriter()\n",
    "for epoch in range(10):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{10}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in train_loader:\n",
    "\n",
    "        print(\"size batch_data[0] : \",batch_data[0].size())\n",
    "        step += 1\n",
    "        inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_len = len(train_ds) // train_loader.batch_size\n",
    "        print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
    "        writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0: # every two epochs : validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_images = None\n",
    "            val_labels = None\n",
    "            val_outputs = None\n",
    "            for val_data in val_loader:\n",
    "                val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
    "                roi_size = (96, 96)\n",
    "                sw_batch_size = 4\n",
    "                val_outputs = sliding_window_inference(val_images, roi_size, sw_batch_size, model)\n",
    "                val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]\n",
    "                # compute metric for current iteration\n",
    "                dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "            # aggregate the final mean dice result\n",
    "            metric = dice_metric.aggregate().item()\n",
    "            # reset the status for next validation round\n",
    "            dice_metric.reset()\n",
    "            metric_values.append(metric)\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), \"best_metric_model_segmentation2d_array.pth\")\n",
    "                print(\"saved new best metric model\")\n",
    "            print(\n",
    "                \"current epoch: {} current mean dice: {:.4f} best mean dice: {:.4f} at epoch {}\".format(\n",
    "                    epoch + 1, metric, best_metric, best_metric_epoch\n",
    "                )\n",
    "            )\n",
    "            writer.add_scalar(\"val_mean_dice\", metric, epoch + 1)\n",
    "            # plot the last model output as GIF image in TensorBoard with the corresponding image and label\n",
    "            plot_2d_or_3d_image(val_images, epoch + 1, writer, index=0, tag=\"image\")\n",
    "            plot_2d_or_3d_image(val_labels, epoch + 1, writer, index=0, tag=\"label\")\n",
    "            plot_2d_or_3d_image(val_outputs, epoch + 1, writer, index=0, tag=\"output\")\n",
    "\n",
    "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
    "writer.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
